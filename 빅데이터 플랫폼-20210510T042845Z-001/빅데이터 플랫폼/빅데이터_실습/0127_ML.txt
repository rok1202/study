1. /var/log/messages 파일 
2. filebeat로 /var/log/messages 로그 파일 수집
3. filebeat에서 kafka로 topic publishing
4. logstash input으로 kafka topic subscribing
5. logstash filter를 이용하여
 - 특정 패턴/필드를 추출하여 별도의 topic으로 지정(INFO 등으로 )
 - 전체 데이터를 별도의 topic으로 (필드 재배치를 하면 좋겠지만)
6. logstash output를 이용하여
 - 전체 데이터를 별도의 인덱스를 이용하여 elasticsearch로 저장
 - 별도추출된 topic을 kafka로 publishing
7. spark에서 별도 topic을 읽어서 ES에 저장


filebeat -> kafka -> logstash -> elasticsearch
https://soye0n.tistory.com/181

카프카 로그 레벨
https://heodolf.tistory.com/30

로그 파일 필터
https://behonestar.tistory.com/90

/var/log/messages 파일 필터
https://sepiros.tistory.com/24

output kafka
https://heodolf.tistory.com/25

kafka to Spark
https://eyeballs.tistory.com/210

참고 
https://facingissuesonit.com/2017/05/06/integrate-logstash-with-kafka/
https://sepiros.tistory.com/24

