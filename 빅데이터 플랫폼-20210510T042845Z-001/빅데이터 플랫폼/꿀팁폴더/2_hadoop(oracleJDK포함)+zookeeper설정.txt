☆★작성자: 양재옥★☆


spark => 2.4.7
Hadoop => 3.1.1
Zookeeper => 3.5.6
Kafka => 2.4.1
==================================================
0. ssh 키 생성
ssh localhost
vi /etc/ssh/sshd_config	--> permitRootlogin 주석해제
service sshd restart
cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys


1. 호스트 이름 변경
cd /proc/sys/kernel
ls hostname
echo hadoop01 > hostname
cat hostname
hostname


2. 방화벽 해제
systemctl stop firewalld
systemctl disable firewalld


3. JDK 설정(Oracle JDK..?)
-openJDK보다 oracle JDK가 더 잘 돌아간다고하니 교체했습니다..굳이안해도됨..!안할거면 바로 4번으로!
3-1) 설치된 자바 패키지 확인
yum list installed java*

3-2) 자바 삭제 명령어
yum remove [삭제할 패키지]
===============예시========================
java-1.7.0-openjdk.x86_64
java-1.7.0-openjdk-headless.x86_64
java-1.8.0-openjdk.x86_64
java-1.8.0-openjdk-devel.x86_64
java-1.8.0-openjdk-headless.x86_64
=======================================

3-3) 자바 설치를 위한 자신의 리눅스 비트 확인
getconf LONG_BIT

3-4) oracle JDK(rpm)다운하여 압축해제 후 /usr/java 밑으로 이동 후 심볼릭 링크 생성
(rpm명령어로 설치하면 /usr/java/에 설치됨)
+ oracle JDK 검색해서 rpm파일 먼저 다운받고!!!
rpm -Uvh jdk-8u271-linux-x64.rpm
ln -s jdk1.8.0_271 java

3-5) java 환경변수 설정(/root/.bash_profile)
export JAVA_HOME=/usr/java/java
export PATH=$PATH:$JAVA_HOME/bin
export CLASSPATH="."

3-6) .bash_profile 적용
source .bash_profile

3-7) java 버전확인
java -version


4. hadoop 설치
1) wget으로 hadoop 3.1.1 다운로드
wget https://archive.apache.org/dist/hadoop/common/hadoop-3.1.1/hadoop-3.1.1.tar.gz

2) 다운로드 후 압축을 풀고 /home/tdata 위치로 파일을 옮긴다음 hadoop으로 심볼릭 링크 생성 
tar -xvzf hadoop-3.1.1.tar.gz
ln -s hadoop-3.1.1 hadoop

#######
참고사이트: https://truman.tistory.com/207
: https://jg-seo.tistory.com/3
: https://parksuseong.blogspot.com/2019/04/312-1-standalone-pseudo-distributed.html
#######

3) vi /root/.bash_profile 환경설정	--> source .bash_profile
export HADOOP_HOME=/home/tdata/hadoop

export HDFS_NAMENODE_USER="root"
export HDFS_DATANODE_USER="root"
export HDFS_SECONDARYNAMENODE_USER="root"
export YARN_RESOURCEMANAGER_USER="root"
export YARN_NODEMANAGER_USER="root"
export YARN_PROXYSERVER_USER="root"

4) hadoop 실행 환경 변수 설정
4-1) vi /home/tdata/hadoop/etc/hadoop/hadoop-env.sh
! export JAVA_HOME=/usr/java/java
! (맨위에 아래의 환경변수 추가)
export HADOOP_HOME=/home/tdata/hadoop
export HADOOP_MAPRED_HOME=$HADOOP_HOME
export HADOOP_COMMON_HOME=$HADOOP_HOME
export HADOOP_HDFS_HOME=$HADOOP_HOME
export YARN_HOME=$HADOOP_HOME
export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop
export YARN_CONF_DIR=$HADOOP_HOME/etc/hadoop

!!여기까지하고 hadoop 실행 명령어해도 사이트는 뜹니당
hadoop 실행명령어 : start-all.sh
(그냥 했을때 안되면 다음의 경로로 가서 실행 /home/tdata/hadoop/sbin/에서 ./start-all.sh 실행)

4-2) vi /home/tdata/hadoop/etc/hadoop/yarn-env.sh
export JAVA_HOME=/usr/java/java
export HADOOP_HOME=/home/tdata/hadoop
export HADOOP_MAPRED_HOME=$HADOOP_HOME
export HADOOP_COMMON_HOME=$HADOOP_HOME
export HADOOP_HDFS_HOME=$HADOOP_HOME
export YARN_HOME=$HADOOP_HOME
export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop
export YARN_CONF_DIR=$HADOOP_HOME/etc/hadoop

4-3) core-site.xml 수정
---------------------------------------------------
<configuration>
 <property>
 <name>fs.defaultFS</name>
 <value>hdfs://localhost:9000</value>
 </property> 
</configuration>
------------------------------------------------
- property 내용 적기
- tmp가 없기 때문에 /home/tdata/hadoop/ 위치에 tmp를 만듦
mkdir /home/tdata/hadoop/tmp

4-4) vi /home/tdata/hadoop/etc/hadoop/hdfs-site.xml
+ hadoop 3버전부터는 50000번대 포트 안먹으니 아래처럼 변경
  <name>dfs.http.address</name>
  <value>hadoop01:9870</value>
  <name>dfs.secondary.http.address</name>
  <value>hadoop01:9868</value>

근데 이거만 써도 됨...
---------------------------------------------------
<configuration>
 <property>
 <name>dfs.replication</name>
 <value>1</value>
 </property> 
</configuration>
---------------------------------------------------

4-5) vi /home/tdata/hadoop/etc/hadoop/mapred-site.xml
...사이트 참고 --> 근데 이거 없어도 될ㄷㅅ..? 이거 하니까 오히려 안되던데..ㅠ그니까 일단 보류...

+hadoop 실행 : start-all.sh
+ firefox에서 아래 주소 접속
localhost:8088
localhost:9870


5. wordcount 예제
(참고사이트 : https://wikidocs.net/63365)
(hadoop fs --> function..?)
cp /home/tdata/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.1.jar ~
hadoop fs -mkdir /input
hadoop fs -ls /
hadoop fs -put /home/tdata/hadoop/README.txt /input/
hadoop jar hadoop-mapreduce-examples-3.1.1.jar wordcount /input /output
hadoop fs -ls /
(localhost:9870 -- > Utilities --> Browse the filesystem 에서도 확인가능)


6. zookeeper 설치
6-1) 주키퍼 설치
wget http://archive.apache.org/dist/zookeeper/zookeeper-3.5.6/apache-zookeeper-3.5.6-bin.tar.gz
tar -zxvf apache-zookeeper-3.5.6.tar.gz
mv apache-zookeeper-3.5.6 /home/tdata/
cd /home/tdata/
ln -s apache-zookeeper-3.5.6 zookeeper

6-2) 주키퍼 데이터 폴더 생성
mkdir -p /home/tdata/data/zookeeper

6-3) 주키퍼 설정
cd /home/tdata/zookeeper/conf
cp zoo_sample.cfg zoo.cfg
vi zoo.cfg
+ 여기에서 12번째 줄 dataDir 수정 후 맨 아래에 서버 추가
12번줄) dataDir=/home/tdata/data/zookeeper
서버추가) server.1=hadoop01:2888:3888

6-4) 데이터폴더에 myid 파일 생성
cd /home/tdata/data/zookeeper
vi myid
-------------------
1
-------------------

6-5) 부팅시 자동으로 실행하도록 서비스 등록
cd /etc/init.d
vi zookeeper-server
------------------------------------------
#!/bin/sh
#
# chkconfig: - 80 05
# description: zookeeper server
#
 
BIN_PATH=/home/tdata/zookeeper/bin
case $1 in
          start)  ${BIN_PATH}/zkServer.sh start   ;;
          stop)  ${BIN_PATH}/zkServer.sh stop;;
          status)  ${BIN_PATH}/zkServer.sh status;;
          restart)  ${BIN_PATH}/zkServer.sh restart;;
              *)  echo "require start|stop|status|restart"  ;;
esac
------------------------------------------

chmod +x zookeeper-server
chkconfig --add zookeeper-server
chkconfig zookeeper-server on

6-6) 서비스 시작해보기(.bash_profile에 ZOOKEEPER_HOME 변수 설정하면 어디서든 할 수 있음)
service zookeeper-server start
(근데 이게 아마 안될거...안되면 /home/tdata/zookeeper/bin/에 가서 ./zkServer.sh start 명령어 해보기)
zkServer.sh status


